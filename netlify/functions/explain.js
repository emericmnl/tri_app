import OpenAI from "openai";

export const handler = async (event) => {
  // ğŸ”’ Ã‰tape 1 : on bloque le GET
  if (event.httpMethod !== "POST") {
    return { statusCode: 405, body: "Method Not Allowed" };
  }

  try {
    // ğŸ” Ã‰tape 2 : on lit le body reÃ§u
    const { ean, material, bac } = JSON.parse(event.body || "{}");
    console.log("ğŸŸ¡ RequÃªte reÃ§ue:", { ean, material, bac });

    // ğŸ”‘ Ã‰tape 3 : on vÃ©rifie la clÃ©
    if (!process.env.OPENAI_API_KEY) {
      console.error("âŒ OPENAI_API_KEY absente !");
      return {
        statusCode: 500,
        body: JSON.stringify({ error: "ClÃ© API manquante" })
      };
    }

    // ğŸ§  Ã‰tape 4 : on prÃ©pare la requÃªte OpenAI
    const client = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
    const prompt = `
      Produit ${ean}, matÃ©riau principal : ${material}, bac : ${bac}.
      Explique simplement pourquoi ce bac est le bon choix de tri.
    `;

    // ğŸ’¬ Ã‰tape 5 : on interroge le modÃ¨le
    const completion = await client.chat.completions.create({
      model: "gpt-4o-mini",
      messages: [{ role: "user", content: prompt }],
      temperature: 0.3
    });

    const text = completion.choices?.[0]?.message?.content?.trim() || "Pas d'explication gÃ©nÃ©rÃ©e.";
    console.log("âœ… RÃ©ponse IA:", text);

    // âœ… Ã‰tape 6 : on renvoie la rÃ©ponse au front
    return {
      statusCode: 200,
      body: JSON.stringify({ explanation: text })
    };

  } catch (err) {
    console.error("ğŸ’¥ Erreur serveur:", err);
    return {
      statusCode: 500,
      body: JSON.stringify({ error: err.message || "Erreur serveur" })
    };
  }
};
